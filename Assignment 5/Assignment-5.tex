\documentclass[12pt,a4paper]{article} 
\renewcommand{\baselinestretch}{1.5}
\usepackage[utf8]{inputenc}
\usepackage[letterspace=2]{microtype}
\usepackage{graphicx}

\begin{document}

%-------------------------------
    %	TITLE SECTION
%-------------------------------
    
    \hrule \medskip % Upper rule
    \begin{minipage}{0.3\textwidth}
    \raggedright
    \small
    \textbf{Suraj Kumar Sahu}
    \\
    19111060
    \\
    BIOMED 5th SEM
    
    \end{minipage}
    \begin{minipage}{0.45\textwidth} 
    \centering 
    \large 
    \textbf{ASSIGNMENT 5}\\
    \normalsize 
    \textbf{Hidden Markov Model}\\ 
    \end{minipage}
    \begin{minipage}{0.2\textwidth}
    \raggedleft
    \today\hfill\\
    \end{minipage}
    \medskip\hrule 
    \bigskip

\subsection*{Introduction}
\textbf{Hidden Markov Model (HMM)} is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states.
\\
\\
Hidden Markov models are especially known for their application in reinforcement learning and temporal pattern recognition such as speech, handwriting, gesture recognition, part-of-speech tagging, musical score following, partial discharges and bioinformatics.
\\
\\
Biological sequence analysis is frequently as simple as affixing the appropriate label to each residue. We want to label nucleotides as exons, introns, or intergenic sequences in gene identification. We want to associate residues in a query sequence with homologous residues in a target database sequence in sequence alignment. 

\subsubsection*{Terminology in HMM}
For example, the term "hidden" refers to the first-order Markov process that lies behind the observation in question. An observation is any data that we are aware of or that we can observe. These HIDDEN STATES can be seen in the following diagram, where "Rainy" interacts with "Sunny".
\\
\begin{figure}[htp]
    \centering
    \includegraphics[width=.55\textwidth]{Hmm.png}
\end{figure}
\\
As shown in the diagram, OBSERVATIONS refers to the words "Walk", "Shop", and "Clean". Our observations are our training data in machine learning, and the number of hidden states is our hyper parameter for our model. The model's evaluation will be discussed in a future post.
\\
\\
\textbf{T} = length of the observation sequence
\\
\textbf{N} = number of states in the model 
\\
\textbf{M} = number of observation symbols
\\
\textbf{Q} = \{ \[q_0,q_1,.... ,q_{N - 1}\] \} = distinct states of the Markov process
\\
\textbf{V} = \{ 0, 1, ..... , M - 1\} = set of possible observations
\\
\textbf{A} = state transition probabilities
\\
\textbf{B} = observation probability matrix
\\
\textbf{$\Pi$} = initial state distribution
\\
\textbf{O} = ( \[ O_0, O_1, ...., O_{T - 1} \] ) = observation sequence.
\end{document}
